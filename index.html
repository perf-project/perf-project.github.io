
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>PERF</title>

    <meta name="description" content="Project page for PERF: Panoramic Neural Radiance Field from a Single Panorama">
    <meta name="viewport" content="width=device-width, initial-scale=1">

        <!--FACEBOOK-->
    <meta property="og:image" content="img/teaser.jpg">
    <meta property="og:image:type" content="image/jpg">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://sparsenerf.github.io/"/>
    <meta property="og:title" content="SparseNeRF" />
    <meta property="og:description" content="Project page for PERF: Panoramic Neural Radiance Field from a Single Panorama" />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SparseNeRF" />
    <meta name="twitter:description" content="Project page for PERF: Panoramic Neural Radiance Field from a Single Panorama" />
    <meta name="twitter:image" content="img/teaser.jpg" />

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="../../stylesheet.css">
    <!-- <link rel="stylesheet" href="css/bootstrap.min.css"> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script type="text/javascript">
        function toggle_visibility(id) {
           var e = document.getElementById(id);
           if(e.style.display == 'block')
              e.style.display = 'none';
           else
              e.style.display = 'block';
        }
        </script>
</head>

<body>
    <script type="importmap">
        {
            "imports": {
                "three": "./js/three.module.js"
            }
        }
    </script>
    <script type="module" src='js/renderer.js'></script>
    <!-- The Modal -->
    <div id="myModal" class="modal">
        <!-- Modal content -->
        <div class="modal-content">
            <!-- <span class="close">&times;</span> -->
            <div class="row" style="align-content: center; width: 100%;">
                <div class="col-lg-8" style='padding-right:5px; padding-left:0px; '>
                    <div id="pano-container" style='text-align: center; height: 100%;'>
                        <img id="pano-img" src="" style="display: none;">
                    </div>
                </div>
                <div class="col-lg-4" style='padding-left:5px; padding-right:0px; height: 100%;'>
                    <div id="threejs-dynamic-container" style='text-align: center; height: 100%;'>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="container" id="main" style="width: 100%; max-width: 1500px;">
        <div class="row">
            <h1 class="col-md-12 text-center">
                <b>PERF</b>: Panoramic Neural Radiance Field from a Single Panorama<br>
                <small>
                    Technical Report 2023
                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://wanggcong.github.io/">
                            Guangcong Wang*<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://quartz-khaan-c6f.notion.site/Peng-Wang-0ab0a2521ecf40f5836581770c14219c">
                            Peng Wang*<sup>2</sup>
                        </a>
                    </li>                    
                    <li>
                        <a href="https://frozenburning.github.io">
                            Zhaoxi Chen<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cs.hku.hk/people/academic-staff/wenping">
                            Wenping Wang<sup>2</sup>
                        </a>
                    </li>                    
                    <li>
                        <a href="https://www.mmlab-ntu.com/person/ccloy/index.html">
                            Chen Change Loy<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="http://liuziwei7.github.io">
                            Ziwei Liu<sup>1</sup>
                        </a>
                    </li>
                    </br>Nanyang Technological University<sup>1</sup>, The University of Hong Kong<sup>2</sup>
                    </br>* denotes equal contribution 
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2303.16196">
                            <image src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01-p-500.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://youtu.be/V0yCTakA964">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/Totoro97/PeRF">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                <strong>TL;DR:</strong> We present PERF, a 360-degree novel view synthesis framework that trains a panoramic neural radiance field from a single panorama.
                </p>
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/input_output_task_definition3.mp4" type="video/mp4"/>
                </video>
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Neural Radiance Field (NeRF) has achieved substantial progress in novel view synthesis given multi-view images. Recently, some works have attempted to train a NeRF from a single image with 3D priors. They mainly focus on a limited field of view and there are few invisible occlusions, which greatly limits their scalability to real-world 360-degree panoramic scenarios with large-size occlusions. In this paper, we present PERF, a 360-degree novel view synthesis framework that trains a panoramic neural radiance field from a single panorama. Notably, PERF allows 3D roaming in a complex scene without expensive and tedious image collection. To achieve this goal, we propose a novel collaborative RGBD inpainting method and a progressive inpainting-and-erasing method to lift up a 360-degree 2D scene to a 3D scene. Specifically, we first predict a panoramic depth map as initialization given a single panorama and reconstruct visible 3D geometry with volume rendering. Then we introduce a collaborative RGBD inpainting approach into a NeRF for completing RGB images and depth maps from random views, deriving from an RGB stable diffusion model and a monocular depth estimator, aiming to generate the 3D geometry and the appearance of invisible regions. Finally, we introduce an inpainting-and-erasing strategy to avoid inconsistent geometry between a newly-added view and reference views. The two components are integrated into the learning of NeRFs in a unified optimization framework and achieves promising results. Extensive experiments on Replica and a new dataset PERF-in-the-wild demonstrate the superiority of our PERF over state-of-the-art methods. Our PERF can be widely used for real-world applications, such as panorama-to-3D, text-to-3D, and 3D scene stylization applications.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Framework
                </h3>
                <p style="text-align:center;">
                    <image src="img/framework_perf_v6_12-1.png" class="img-responsive" alt="scales">
                </p>
                <p class="text-justify">
                    PERF mainly consists of three modules, including 1) single-view NeRF training with depth maps; 2) collaborative RGBD inpainting; and 3) progressive inpainting-and-erasing. 
  Specifically, given a single panorama, we predict its depth map with a Depth Estimation model and train a NeRF with the input view as initialization. Then a collaborative RGBD inpainting module that contains a Depth Estimator and a Stable Diffusion is proposed to extend NeRF to random views. To avoid geometry conflict, a progressive inpainting-and-erasing module is used to compute a mask of the conflicted regions and eliminate these regions. We fine-tune the panoramic NeRF with the reference single-view panorama and new panoramas generated from random viewpoints until convergence.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Demo Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/4wa2h1fjh2U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Application 1: Single Panorama to 3D
                </h3>
                <br>
                <video id="v1" width="100%" autoplay loop muted controls>
                    <source src="img/app1_5_reduced_clipped.mp4" type="video/mp4"/>
                </video>
            </div>
        </div>

         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Application 2: Text to 3D Scene 
                </h3>
                <h4>
                Text to 3D Scene = Text to 2D Panorama + 2D Panorama to 3D Scene (PERF)
                <h4>
                <br>
                <video id="v2" width="100%" autoplay loop muted controls>
                    <source src="img/app2_1_new.mp4" type="video/mp4"/>
                </video>
            </div>
        </div>   
         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <br>
                <video id="v2_2" width="100%" autoplay loop muted controls>
                    <source src="img/app2_2_new.mp4" type="video/mp4"/>
                </video>
            </div>
        </div>  
          <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <br>
                <video id="v2_3" width="100%" autoplay loop muted controls>
                    <source src="img/app2_3_new.mp4" type="video/mp4"/>
                </video>
            </div>
        </div>        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Application 3: 3D Stylization
                </h3>
                <h4>
                3D Stylization = 2D Panorama Stylization + 2D Panorama to 3D Scene (PERF)
                <h4>
                <br>
                <video id="v3" width="100%" autoplay loop muted controls>
                    <source src="img/app3_3.mp4" type="video/mp4"/>
                </video>
            </div>
        </div>    
    
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10" style="padding: 0%; margin: 0%;">
                    <textarea id="bibtex" class="form-control" readonly>
@article{perf2023,
    title={PERF: Panoramic Neural Radiance Field from a Single Panorama},
    author={Guangcong and Peng Wang and Zhaoxi Chen and Wenping Wang and Chen Change Loy and Ziwei Liu},
    journal={Technical Report},
    year={2023}}
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related Links
                </h3>
                <p class="text-justify">
                    <a href="https://scene-dreamer.github.io/">SceneDreamer</a>: Unbounded 3D Scene Generation from 2D Image Collections. <br>
                    <a href="https://classifier-as-generator.github.io/">CaG</a>: Traditional Classification Neural Networks are Good Generators: They are Competitive with DDPMs and GANs.<br>
                    <a href="https://sparsenerf.github.io/">SparseNeRF</a>: Novel view synthesis with sparse views. <br>
                    <a href="http://totoro97.github.io/projects/f2-nerf/">F2-NeRF</a>: Fast Neural Radiance Field Training with Free Camera. <br>
                    <a href="https://lingjie0206.github.io/papers/NeuS/">NeuS</a>: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction. <br>
                    <a href="https://frozenburning.github.io/projects/text2light/">Text2light</a>: Zero-Shot Text-Driven HDR Panorama Generation. <br>
                    <a href="https://style-light.github.io/">StyleLight</a> generates HDR indoor panorama from a limited FOV image. <br>
                    <a href="https://fast-vid2vid.github.io/">Fast-Vid2Vid</a>: Spatial-Temporal Compression for Video-to-Video Synthesis. <br>
                    <a href="https://hongfz16.github.io/projects/AvatarCLIP.html">AvatarCLIP</a> proposes a zero-shot text-driven framework for 3D avatar generation and animation. <br>
                    <a href="https://yumingj.github.io/projects/Text2Human.html">Text2Human</a> proposes a text-driven controllable human image generation framework. <br>
                    <a href="https://frozenburning.github.io/projects/relighting4d/">Relighting4D</a> can relight human actors using the HDRI generated by us. <br>
                    <a href="https://jiepengwang.github.io/NeuRIS/">NeuRIS</a>: Neural Reconstruction of Indoor Scenes Using Normal Priors. <br>
                    <a href="https://skhu101.github.io/SHERF/">SHERF</a>: Generalizable Human NeRF from a Single Image. <br>
                    <a href="https://hongfz16.github.io/projects/EVA3D.html">EVA3D</a>: Compositional 3D Human Generation.<br>
from 2D Image Collections
. <br>
                </p>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgments
                </h3>
                <p class="text-justify">
                    This work is supported by the National Research Foundation, Singapore under its AI Singapore Programme, NTU NAP, MOE AcRF Tier 2 (T2EP20221-0033), and under the RIE2020 Industry Alignment Fund - Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from the industry partner(s).
                    <br>
                The website template is borrowed from <a href="https://jonbarron.info/mipnerf/">Mip-NeRF</a>.
                </p>
                <br>
            </div>
        </div>

         

    
    <!-- this is comment-->
            

    <!-- <div class="section" style="width:200px; margin-left: 40%;">  -->
    <div class="section" style="text-align:center; padding:0 0 20px 0">
        <a href="https://clustrmaps.com/site/1bx12" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=4MTh2JI6cGC39moXVqUZe4yLl5VcR5osM325FNvfrhk&cl=ffffff"></a>
    </div>


            
  </div> <!-- #content -->           
                    
  </div>
</body>

</html>
